{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP-fjjcwHkgK"
   },
   "source": [
    "All 7 features : PRECT, QBP, TBP, SOLIN, PS, SHFLX, LHFLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EpQ2Ko_PT3ty"
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as s\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpISX_wcZAtO"
   },
   "outputs": [],
   "source": [
    "# TODO: Enter the path to the stored pickle file\n",
    "d_vars = pickle.load(open('data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EpSnXYV6EuUy"
   },
   "outputs": [],
   "source": [
    "d_vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "et2CVyFfJYo2"
   },
   "outputs": [],
   "source": [
    "d_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9V4vkrNERAM"
   },
   "outputs": [],
   "source": [
    "# We will only use non-zero values of PRECT to train our network\n",
    "d_non_zero = d_vars[d_vars.PRECT>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rkqt4pBgOE6D"
   },
   "outputs": [],
   "source": [
    "d_non_zero.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4rxzOvK5T8pd"
   },
   "source": [
    "#### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "107ERkh6WLuW"
   },
   "outputs": [],
   "source": [
    "d_non_zero.loc[:,'PRECT_NEW'] = s.boxcox(d_non_zero.PRECT, 0.1)\n",
    "d_non_zero.loc[:,'QBP_NEW'] = d_non_zero.QBP**(1/4)\n",
    "d_non_zero.loc[:,'SHFLX_NEW'] = d_non_zero.SHFLX*(10**(-2))\n",
    "d_non_zero.loc[:,'LHFLX_NEW'] = d_non_zero.LHFLX*(10**(-2))\n",
    "d_non_zero.loc[:,'PS_NEW'] = d_non_zero.PS*(10**(-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgHex_BbBgOc"
   },
   "outputs": [],
   "source": [
    "d_non_zero = (d_non_zero).astype({'QBP_NEW': 'float32','LHFLX_NEW': 'float32','SHFLX_NEW': 'float32','PS_NEW': 'float32'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0rijFRyUXGV"
   },
   "source": [
    "#### Plot the transformed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwEDvqnBUfCn"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "vars_to_plot = ['PRECT_NEW', 'QBP_NEW', 'SHFLX_NEW', 'LHFLX_NEW', 'PS_NEW']\n",
    "for i, var in enumerate(vars_to_plot):\n",
    "  plt.subplot(3,3,i+1)\n",
    "  plt.hist(d_non_zero[var], density=True, bins=20)\n",
    "  plt.xlabel('Transformed '+var)\n",
    "  plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idikC681W_gt"
   },
   "outputs": [],
   "source": [
    "d_non_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Fh5SHj1nd0n"
   },
   "outputs": [],
   "source": [
    "d_non_zero.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ih35Dct7q-m1"
   },
   "outputs": [],
   "source": [
    "# TODO: Select which features to train the GAN on\n",
    "# (keep in mind what features you select should effect the architecture of the model - ideally for more features you will need a deeper model)\n",
    "data=np.array(d_non_zero[['PRECT_NEW','QBP_NEW','PS_NEW','TBP','SHFLX_NEW','LHFLX_NEW']])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cku0eSlDQNa"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxddxVeWRoAx"
   },
   "source": [
    "### GAN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With noisy 0 to 0.2 range of labels for real data, 0.8 to 1 range of labels for fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mn3gZNyon2zv"
   },
   "outputs": [],
   "source": [
    "# TODO: Set the batch size\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SqLTo-GVUkZ"
   },
   "outputs": [],
   "source": [
    "# Num batches\n",
    "num_batches = len(data_loader)\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hq3LBorVWcZ"
   },
   "source": [
    "##### Define Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlaJD6s2rOFK"
   },
   "outputs": [],
   "source": [
    "# TODO: Modify the architecture if needed\n",
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        # TODO: modify n_features if fewer variables selected\n",
    "        n_features = 6\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "  \n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden3 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden4 = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden5 = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x.cuda())\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.hidden5(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "discriminator = DiscriminatorNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2lBT25TbDea"
   },
   "source": [
    "##### Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWbvwh9fsdn6"
   },
   "outputs": [],
   "source": [
    "# TODO: Modify the architecture if needed\n",
    "class GeneratorNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 100\n",
    "        # TODO: modify n_out if fewer variables selected\n",
    "        n_out = 6\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.ReLU(),\n",
    "  \n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden3 = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden4 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden5 = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x.cuda())\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.hidden5(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "generator = GeneratorNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJkJrsS9uI0V"
   },
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xfxxaHj6s_Xy"
   },
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    '''\n",
    "    Generates a 1-d vector of gaussian sampled random values\n",
    "    for input to the Generator\n",
    "    '''\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    n.cuda()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-l-W9ONtEQw"
   },
   "outputs": [],
   "source": [
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0004)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iD2ShBkQtGYc"
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naOHNZcZuQQu"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWXau-AKtIPc"
   },
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, data, labels):\n",
    "    N = real_data.size(0)\n",
    "\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction = discriminator(data)\n",
    "    prediction.cuda()\n",
    "\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    error_total = loss(prediction, labels)\n",
    "    error_total.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error and predictions for real and fake inputs\n",
    "    return error_total, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LE6ASu6Vf2WO"
   },
   "outputs": [],
   "source": [
    "def train_generator(optimizer, fake_data, labels):\n",
    "    N = fake_data.size(0)\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    prediction.cuda()\n",
    "\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    # Calculate error and backpropagate\n",
    "    error = loss(prediction, labels)\n",
    "\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXcl-CZbbASY"
   },
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4DRn3K5cOl8"
   },
   "source": [
    "##### Add a path to a checkpoint folder to store training checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gz3zdUPPa__h"
   },
   "outputs": [],
   "source": [
    "# TODO: Add correct path\n",
    "drive_root = \"/content/drive/My Drive/Capstone Project/GAN-Capstone/\"\n",
    "checkpoint_dir = os.path.join(drive_root, \"checkpoints\")\n",
    "# your name here\n",
    "checkpoint_dir = os.path.join(checkpoint_dir, \"aashna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_dQ551PuzAY"
   },
   "outputs": [],
   "source": [
    "# TODO: if you are starting training from scratch, make sure you rm -r the contents of the checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dniSg7d1bNs4"
   },
   "outputs": [],
   "source": [
    "print(\"Checkpoints directory is\", checkpoint_dir)\n",
    "if os.path.exists(checkpoint_dir):\n",
    "  print(\"Checkpoints folder already exists\")\n",
    "else:\n",
    "  print(\"Creating a checkpoints directory\")\n",
    "  os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_nz1Whrfbvl"
   },
   "outputs": [],
   "source": [
    "# Restore the latest checkpoints\n",
    "chkpts = os.listdir(checkpoint_dir)\n",
    "if chkpts:\n",
    "  latest = chkpts[0]\n",
    "  print(latest)\n",
    "  saved = torch.load(checkpoint_dir+'/'+latest)\n",
    "  generator.load_state_dict(saved['gen_state_dict'])\n",
    "  discriminator.load_state_dict(saved['disc_state_dict'])\n",
    "  g_optimizer.load_state_dict(saved['gen_optimizer_state_dict'])\n",
    "  d_optimizer.load_state_dict(saved['disc_optimizer_state_dict'])\n",
    "  current_epoch = saved['epoch']+1\n",
    "  g_error = saved['gen_loss']\n",
    "  d_error = saved['disc_loss']\n",
    "else:\n",
    "  current_epoch = 0\n",
    "\n",
    "current_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-aXVcssunNC"
   },
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jcRsDpmdSyr"
   },
   "outputs": [],
   "source": [
    "# TODO: Set the number of epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(current_epoch, num_epochs):\n",
    "  # TODO: modify the columns of the result dataframe if fewer variables selected\n",
    "  results = pd.DataFrame(columns=['Prect','QBP','PS','TBP','SHFLX','LHFLX'])\n",
    "  for n_batch,real_batch in enumerate(data_loader):\n",
    "    N = real_batch.size(0)\n",
    "\n",
    "    # 1. Train Discriminator\n",
    "    real_data = real_batch\n",
    "    real_data.cuda()\n",
    "\n",
    "    # Generate fake data and detach \n",
    "    # (so gradients are not calculated for generator)\n",
    "    noi = noise(N)\n",
    "    noi.cuda()\n",
    "\n",
    "    fake_data = generator(noi).detach()\n",
    "    fake_data.cuda()\n",
    "\n",
    "    one_prec_N = int((int(0.1*N)+1)/2)\n",
    "\n",
    "     \n",
    "    # for real data\n",
    "    y_dis0 = np.zeros(N)\n",
    "    y_dis0[:N-one_prec_N] = np.random.uniform(0.0,0.2000000001,N-one_prec_N)\n",
    "    y_dis0[N-one_prec_N:] = np.random.uniform(0.8,1.0000000001,one_prec_N)\n",
    "    random.shuffle(y_dis0)\n",
    "\n",
    "    # for fake data\n",
    "    y_dis1 = np.ones(N)\n",
    "    y_dis1[:N-one_prec_N]= np.random.uniform(0.8,1.0000000001,N-one_prec_N)\n",
    "    y_dis1[N-one_prec_N:]= np.random.uniform(0.0,0.2000000001,one_prec_N)\n",
    "    random.shuffle(y_dis1)\n",
    "\n",
    "    y_dis = np.concatenate((y_dis0,y_dis1),axis=0)\n",
    "\n",
    "\n",
    "    y_torch = Variable(torch.from_numpy(y_dis).float())\n",
    "    y_torch.cuda()\n",
    "    \n",
    "    #Train D\n",
    "    error_real, pred_real = train_discriminator(d_optimizer, real_data ,Variable(torch.from_numpy(y_dis0).float()))\n",
    "    error_fake, pred_fake = train_discriminator(d_optimizer, fake_data ,Variable(torch.from_numpy(y_dis1).float()))\n",
    "\n",
    "    \n",
    "    d_error = error_real + error_fake\n",
    "\n",
    "    d_pred = []\n",
    "    d_pred.append(pred_real)\n",
    "    d_pred.append(pred_fake)    \n",
    "\n",
    "    # 2. Train Generator\n",
    "    fake_data = generator(noise(N))\n",
    "    fake_data.cuda()\n",
    "    \n",
    "    # Train G\n",
    "    y_gen = np.zeros(N)\n",
    "    y_torch_gen = Variable(torch.from_numpy(y_gen).float())\n",
    "    y_torch_gen.cuda()\n",
    "\n",
    "    g_error = train_generator(g_optimizer, fake_data, y_torch_gen)\n",
    "\n",
    "    if (n_batch) % 100 == 0: \n",
    "      print('Epoch: {},\\nDiscriminator Loss: {},\\nGenerator Loss: {},\\nGenerated Data: {}'.format(epoch+1,\n",
    "                                                                                               d_error.cpu().detach().numpy(),\n",
    "                                                                                               g_error.cpu().detach().numpy(),\n",
    "                                                                                               fake_data[0].cpu().detach().numpy()))\n",
    "\n",
    "    results = results.append(pd.DataFrame(fake_data.tolist(), columns=results.columns))\n",
    "  \n",
    "  # save weights for the current epoch\n",
    "  checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pt')\n",
    "  torch.save({'epoch': epoch,\n",
    "              'gen_state_dict': generator.state_dict(),\n",
    "              'disc_state_dict': discriminator.state_dict(),\n",
    "              'gen_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "              'disc_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "              'gen_loss': g_error,\n",
    "              'disc_loss': d_error,},\n",
    "             checkpoint_path)\n",
    "  \n",
    "  # TODO: specify path to store the results at the end of the epoch\n",
    "  pickle.dump(results, open('results.pkl', 'wb'))\n",
    "  print('Saved model at ', checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRMjVJqph5Zq"
   },
   "source": [
    "### Explore the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4vRE_QmVR0Y"
   },
   "outputs": [],
   "source": [
    "# load results\n",
    "results = pickle.load(open('results.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFsI9xu1r9_n"
   },
   "outputs": [],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgTabNWkinWP"
   },
   "source": [
    "##### Inverse transform the data to get values in the correct range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQqlJNif5I7M"
   },
   "outputs": [],
   "source": [
    "q = results.QBP**4\n",
    "p = s.inv_boxcox(results.Prect, 0.1)\n",
    "t = results.TBP\n",
    "ps = (results.PS) * (10**4)\n",
    "sh = (results.SHFLX) * (10**2)\n",
    "lh = (results.LHFLX) * (10**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ccq2WmEpa8a"
   },
   "outputs": [],
   "source": [
    "ans = pd.concat([p.reset_index(drop=True),\n",
    "                 q.reset_index(drop=True),\n",
    "                 t.reset_index(drop=True),\n",
    "                 ps.reset_index(drop=True),\n",
    "                 sh.reset_index(drop=True),\n",
    "                 lh.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPJZ8eMhrExb"
   },
   "outputs": [],
   "source": [
    "ans.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDXGrhFJiyst"
   },
   "source": [
    "##### A scatter plot of PRECT vs QBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTz5gG1rpRtk"
   },
   "outputs": [],
   "source": [
    "plt.scatter(ans.QBP, ans.Prect, alpha = 0.2)\n",
    "plt.xlabel('QBP')\n",
    "plt.ylabel('PRECT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4b86tHRi6VB"
   },
   "source": [
    "##### A scatter plot of PRECT vs TBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skyqMm6Czrcj"
   },
   "outputs": [],
   "source": [
    "plt.scatter(ans.TBP, ans.Prect, alpha=0.2)\n",
    "plt.xlabel('TBP')\n",
    "plt.ylabel('PRECT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SG3_3DgSi8iO"
   },
   "source": [
    "##### Distribution of all generated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSEgDiUAqo4P"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "vars_to_plot = results.columns.to_list()\n",
    "for i, var in enumerate(vars_to_plot):\n",
    "  plt.subplot(3,3,i+1)\n",
    "  plt.hist(results[var], density=True, bins=20)\n",
    "  plt.xlabel('Predicted '+var)\n",
    "  plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_d7Y0d-jAn0"
   },
   "source": [
    "##### Plot variance of PRECT vs Bins of QBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlDfIav8-fWj"
   },
   "outputs": [],
   "source": [
    "ans_sorted = ans.sort_values(by='QBP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6S1HNd0qXKH"
   },
   "outputs": [],
   "source": [
    "prect_vars_result = []\n",
    "qbp_bins_result_str = []\n",
    "for split in np.array_split(ans_sorted,10,axis = 0):\n",
    "  prect_vars_result.append(np.std(split.Prect)**2)\n",
    "  qbp_bins_result_str.append(\"{:.3f}\".format(split.QBP.min()*(10**3))+\" - \"+\"{:.3f}\".format(split.QBP.max()*(10**3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0VKPyoGqXIF"
   },
   "outputs": [],
   "source": [
    "plt.plot(prect_vars_result)\n",
    "plt.xticks(list(range(0,10)),labels=qbp_bins_result_str,rotation=90)\n",
    "plt.xlabel('QBP Range (1e-3)')\n",
    "plt.ylabel('PRECT Variance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Train_GAN_7_features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
