{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_GAN_four_features.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wxddxVeWRoAx",
        "fjpgIIvUbFjf"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLMPHLnx5VIt",
        "colab_type": "text"
      },
      "source": [
        "### Trained the GAN for 1300 epochs\n",
        "\n",
        "4 features : PRECT, QBP, PS, TBP\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpQ2Ko_PT3ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as s\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import seaborn as sns\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS6iu6bbWTwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Enter the path to the stored pickle file\n",
        "d_vars = pickle.load(open('data.pkl','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9V4vkrNERAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will only use non-zero values of PRECT to train our network\n",
        "d_non_zero = d_vars[d_vars.PRECT>0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkqt4pBgOE6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_non_zero.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJGAyysTOQ1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_non_zero.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbwyCpEXxrs3",
        "colab_type": "text"
      },
      "source": [
        "#### Feature Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "107ERkh6WLuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_non_zero['PRECT_NEW'] = s.boxcox(d_non_zero.PRECT, 0.1)\n",
        "d_non_zero['QBP_NEW'] = d_non_zero.QBP**(1/4) #s.boxcox(d_non_zero.QBP, 0.4)\n",
        "d_non_zero['SHFLX_NEW'] = d_non_zero.SHFLX*(10**(-2))\n",
        "d_non_zero['LHFLX_NEW'] = d_non_zero.LHFLX*(10**(-2))\n",
        "d_non_zero['PS_NEW'] = d_non_zero.PS*(10**(-4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgHex_BbBgOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_non_zero = (d_non_zero).astype({'QBP_NEW': 'float32','LHFLX_NEW': 'float32','SHFLX_NEW': 'float32','PS_NEW': 'float32'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxZWU5vwCO48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_non_zero.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUVXBJnNXJv7",
        "colab_type": "text"
      },
      "source": [
        "###### Plot the transformed features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJKb1KdH2Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20,15))\n",
        "vars_to_plot = ['PRECT_NEW', 'QBP_NEW', 'PS_NEW']\n",
        "for i, var in enumerate(vars_to_plot):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.hist(d_non_zero[var], density=True, bins=20)\n",
        "  plt.xlabel('Transformed '+var)\n",
        "  plt.ylabel('Density')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih35Dct7q-m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Select which features to train the GAN on\n",
        "# (keep in mind what features you select should effect the architecture of the model - ideally for more features you will need a deeper model)\n",
        "data=np.array(d_non_zero[['PRECT_NEW','QBP_NEW','PS_NEW','TBP']])\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cku0eSlDQNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxddxVeWRoAx",
        "colab_type": "text"
      },
      "source": [
        "### GAN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK-PqM0iddH2",
        "colab_type": "text"
      },
      "source": [
        "With noisy 0 to 0.2 range of labels for real data, 0.8 to 1 range of labels for fake data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn3gZNyon2zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Set the batch size\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=1024, shuffle=False)\n",
        "\n",
        "# Num batches\n",
        "num_batches = len(data_loader)\n",
        "num_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jUxrAdwXndI",
        "colab_type": "text"
      },
      "source": [
        "###### Define Discriminator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlaJD6s2rOFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Modify the architecture if needed\n",
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        # TODO: modify n_features if more variables selected\n",
        "        n_features = 4\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "  \n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden3 = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(128, n_out),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x.cuda())\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.hidden3(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "discriminator = DiscriminatorNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymAAvqPOX0Bv",
        "colab_type": "text"
      },
      "source": [
        "###### Define Generator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWbvwh9fsdn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Modify the architecture if needed\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 100\n",
        "        # TODO: modify n_out if more variables selected\n",
        "        n_out = 4\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 256),\n",
        "            nn.ReLU(),\n",
        "  \n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden3 = nn.Sequential(\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(256, n_out),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x.cuda())\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.hidden3(x)\n",
        "        \n",
        "        x = self.out(x)\n",
        "        return x\n",
        "generator = GeneratorNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DWI2eSnyXTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda=True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    discriminator.cuda()\n",
        "    generator.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfxxaHj6s_Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    n.cuda()\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-l-W9ONtEQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0004)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD2ShBkQtGYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUjUovJ_ydxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWXau-AKtIPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(optimizer, data, labels):\n",
        "\n",
        "    N = real_data.size(0)\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction = discriminator(data)\n",
        "    prediction.cuda()\n",
        "    labels = labels.cuda()\n",
        "    \n",
        "    error_total = loss(prediction, labels)\n",
        "    error_total.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error and predictions for real and fake inputs\n",
        "    return error_total, prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE6ASu6Vf2WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_generator(optimizer, fake_data, labels):\n",
        "    N = fake_data.size(0)\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "    prediction.cuda()\n",
        "\n",
        "    labels = labels.cuda()\n",
        "    \n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction, labels)\n",
        "\n",
        "    error.backward()\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXcl-CZbbASY",
        "colab_type": "text"
      },
      "source": [
        "### Checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L_LYDnBYYlN",
        "colab_type": "text"
      },
      "source": [
        "Add a path to a checkpoint folder to store training checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz3zdUPPa__h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Add correct path\n",
        "drive_root = \"/content/drive/My Drive/Capstone Project/GAN-Capstone/\"\n",
        "checkpoint_dir = os.path.join(drive_root, \"checkpoints\")\n",
        "# your name here\n",
        "checkpoint_dir = os.path.join(checkpoint_dir, \"akshata\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YXKCUDjYqcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO: if you are starting training from scratch, make sure you rm -r the contents of the checkpoint directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dniSg7d1bNs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Checkpoints directory is\", checkpoint_dir)\n",
        "if os.path.exists(checkpoint_dir):\n",
        "  print(\"Checkpoints folder already exists\")\n",
        "else:\n",
        "  print(\"Creating a checkpoints directory\")\n",
        "  os.makedirs(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_nz1Whrfbvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Restore the latest checkpoints\n",
        "chkpts = os.listdir(checkpoint_dir)\n",
        "if chkpts:\n",
        "  latest = chkpts[0]\n",
        "  print(latest)\n",
        "  saved = torch.load(checkpoint_dir+'/'+latest)\n",
        "  generator.load_state_dict(saved['gen_state_dict'])\n",
        "  discriminator.load_state_dict(saved['disc_state_dict'])\n",
        "  g_optimizer.load_state_dict(saved['gen_optimizer_state_dict'])\n",
        "  d_optimizer.load_state_dict(saved['disc_optimizer_state_dict'])\n",
        "  current_epoch = saved['epoch']+1\n",
        "  g_error = saved['gen_loss']\n",
        "  d_error = saved['disc_loss']\n",
        "else:\n",
        "  current_epoch = 0\n",
        "\n",
        "current_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frk9h4Sly12k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jcRsDpmdSyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Set the number of epochs\n",
        "num_epochs = 1300\n",
        "\n",
        "for epoch in range(current_epoch, num_epochs):\n",
        "  \n",
        "  # TODO: modify the columns of the result dataframe if more variables selected\n",
        "  results = pd.DataFrame(columns=['Prect','QBP','PS','TBP'])\n",
        "\n",
        "  for n_batch,real_batch in enumerate(data_loader):\n",
        "    N = real_batch.size(0)\n",
        "   \n",
        "    # 1. Train Discriminator\n",
        "    real_data = real_batch\n",
        "    real_data.cuda()\n",
        "    \n",
        "    # Generate fake data and detach \n",
        "    # (so gradients are not calculated for generator)\n",
        "    noi = noise(N)\n",
        "    noi.cuda()\n",
        "\n",
        "    fake_data = generator(noi).detach()\n",
        "    fake_data.cuda()\n",
        "\n",
        "    ## add one percent noise to the labels\n",
        "    one_prec_N = int((int(0.1*N)+1)/2)\n",
        "\n",
        "    ## for real data - randomly shuffled labels in range from 0 to 0.2\n",
        "    y_dis0 = np.zeros(N)\n",
        "    y_dis0[:N-one_prec_N] = np.random.uniform(0.0,0.2000000001,N-one_prec_N)\n",
        "    y_dis0[N-one_prec_N:] = np.random.uniform(0.8,1.0000000001,one_prec_N)\n",
        "    random.shuffle(y_dis0)\n",
        "\n",
        "    ## for fake data - randomly shuffled labels in range from 0.8 to 1.0\n",
        "    y_dis1 = np.ones(N)\n",
        "    y_dis1[:N-one_prec_N]= np.random.uniform(0.8,1.0000000001,N-one_prec_N)\n",
        "    y_dis1[N-one_prec_N:]= np.random.uniform(0.0,0.2000000001,one_prec_N)\n",
        "    random.shuffle(y_dis1)\n",
        "\n",
        "    y_dis = np.concatenate((y_dis0,y_dis1),axis=0)\n",
        "    y_torch = Variable(torch.from_numpy(y_dis).float())\n",
        "    y_torch.cuda()\n",
        "    \n",
        "    #Train D\n",
        "    error_real, pred_real = train_discriminator(d_optimizer, real_data ,Variable(torch.from_numpy(y_dis0).float()))\n",
        "    error_fake, pred_fake = train_discriminator(d_optimizer, fake_data ,Variable(torch.from_numpy(y_dis1).float()))\n",
        "\n",
        "    \n",
        "    d_error = error_real + error_fake\n",
        "\n",
        "    d_pred = []\n",
        "    d_pred.append(pred_real)\n",
        "    d_pred.append(pred_fake)    \n",
        "\n",
        "    # 2. Train Generator\n",
        "    fake_data = generator(noise(N))\n",
        "    fake_data.cuda()\n",
        "    \n",
        "    # Train G\n",
        "    y_gen = np.zeros(N)\n",
        "    y_torch_gen = Variable(torch.from_numpy(y_gen).float())\n",
        "    y_torch_gen.cuda()\n",
        "\n",
        "    g_error = train_generator(g_optimizer, fake_data, y_torch_gen)\n",
        "\n",
        "    # print d error and g error\n",
        "    if (n_batch) % 100 == 0: \n",
        "      \"\"\"logger.display_status(\n",
        "                  epoch, num_epochs, n_batch, num_batches,\n",
        "                  d_error, g_error\n",
        "              )\"\"\"\n",
        "      print(d_error,g_error,fake_data[0],epoch)\n",
        "    \n",
        "    results = results.append(pd.DataFrame(fake_data.tolist(), columns=results.columns))\n",
        "  \n",
        "  # save checkpoint\n",
        "  checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pt')\n",
        "  torch.save({'epoch': epoch,\n",
        "              'gen_state_dict': generator.state_dict(),\n",
        "              'disc_state_dict': discriminator.state_dict(),\n",
        "              'gen_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "              'disc_optimizer_state_dict': d_optimizer.state_dict(),\n",
        "              'gen_loss': g_error,\n",
        "              'disc_loss': d_error,},\n",
        "             checkpoint_path)\n",
        "  \n",
        "  ## TODO:  specify your results pickle file here\n",
        "  pickle.dump(results, open('results_akshata_new.pkl', 'wb'))\n",
        "  print('Saved model at ', checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjpgIIvUbFjf",
        "colab_type": "text"
      },
      "source": [
        "##### Explore the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4vRE_QmVR0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = pickle.load(open('results_akshata_new.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFsI9xu1r9_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUeyCv5zbL2q",
        "colab_type": "text"
      },
      "source": [
        "Inverse transform the data to get values in the correct range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQqlJNif5I7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q = results.QBP**4\n",
        "p = s.inv_boxcox(results.Prect, 0.1)\n",
        "t = results.TBP\n",
        "ps = (results.PS) * (10**4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ccq2WmEpa8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = pd.concat([p.reset_index(drop=True),\n",
        "                 q.reset_index(drop=True),\n",
        "                 t.reset_index(drop=True),\n",
        "                 ps.reset_index(drop=True),\n",
        "                 ], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJZ8eMhrExb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPfd13U3bT_i",
        "colab_type": "text"
      },
      "source": [
        "A scatter plot of PRECT vs QBP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTz5gG1rpRtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(ans.QBP, ans.Prect, alpha = 0.2)\n",
        "plt.xlabel('QBP')\n",
        "plt.ylabel('PRECT')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVJiuSSgbXd8",
        "colab_type": "text"
      },
      "source": [
        "A scatter plot of PRECT vs TBP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skyqMm6Czrcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(ans.TBP, ans.Prect, alpha=0.2)\n",
        "plt.xlabel('TBP')\n",
        "plt.ylabel('PRECT')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av5j4FkHbavJ",
        "colab_type": "text"
      },
      "source": [
        "Distribution of all generated variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSEgDiUAqo4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20,15))\n",
        "vars_to_plot = results.columns.to_list()\n",
        "for i, var in enumerate(vars_to_plot):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.hist(results[var], density=True, bins=20)\n",
        "  plt.xlabel('Predicted '+var)\n",
        "  plt.ylabel('Density')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpdttw2dbdrm",
        "colab_type": "text"
      },
      "source": [
        "Plot variance of PRECT vs Bins of QBP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlDfIav8-fWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans_sorted = ans.sort_values(by='QBP')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6S1HNd0qXKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prect_vars_result = []\n",
        "qbp_bins_result_str = []\n",
        "for split in np.array_split(ans_sorted,10,axis = 0):\n",
        "  prect_vars_result.append(np.std(split.Prect)**2)\n",
        "  qbp_bins_result_str.append(\"{:.3f}\".format(split.QBP.min()*(10**3))+\" - \"+\"{:.3f}\".format(split.QBP.max()*(10**3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0VKPyoGqXIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(prect_vars_result)\n",
        "plt.xticks(list(range(0,10)),labels=qbp_bins_result_str,rotation=90)\n",
        "plt.xlabel('QBP Range (1e-3)')\n",
        "plt.ylabel('PRECT Variance')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msw3GnpXBm_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}