{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_GAN_three_features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpQ2Ko_PT3ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as s\n",
        "import pickle\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiIRohEVXhqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_vars = pickle.load(open('data.pkl','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpSnXYV6EuUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_vars.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5eF-6aNijRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_vars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVZz3F3OeoP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_vars = d_vars.pivot_table('vars',['lat','lon','time'],'var_names').reset_index()\n",
        "d_non_zero = d_vars[d_vars.PRECT>0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqP7tpnavzbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(s.boxcox(d_non_zero.PRECT,0.1),density=True,bins=20)\n",
        "plt.xlabel('BoxCox Transform of PRECT')\n",
        "plt.ylabel('Density')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "107ERkh6WLuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_non_zero['PRECT_NEW'] = s.boxcox(d_non_zero.PRECT, 0.1)\n",
        "d_non_zero['QBP_NEW'] = d_non_zero.QBP**(1/4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMh9k3qMG5a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_non_zero = (d_non_zero).astype({'QBP_NEW': 'float32'})\n",
        "d_non_zero.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unJfTr4JHCwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=np.array(d_non_zero[['PRECT_NEW','QBP_NEW','TBP']])\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJKb1KdH2Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(d_non_zero.PRECT_NEW.values, density=True, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fh5SHj1nd0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_non_zero.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih35Dct7q-m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=np.array(d_non_zero[['PRECT_NEW','QBP_NEW','TBP']])\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p0uShRqq6rw",
        "colab_type": "text"
      },
      "source": [
        "Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn3gZNyon2zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(data, batch_size=1024, shuffle=False)\n",
        "# Num batches\n",
        "num_batches = len(data_loader)\n",
        "num_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlaJD6s2rOFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        n_features = 3\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "  \n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(256, n_out),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x.cuda())\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "discriminator = DiscriminatorNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWbvwh9fsdn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 100\n",
        "        n_out = 3\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 256),\n",
        "            nn.ReLU(),\n",
        "  \n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # self.last_in1 = nn.Linear(1024, 1)\n",
        "        # self.last_in2 = nn.Linear(1024, 1)\n",
        "        self.last_in3 = nn.Linear(1024, 1)\n",
        "        self.last_in4 = nn.Linear(1024, 2)\n",
        "        self.act4 = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x.cuda())\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        # x1 = self.last_in1(x)\n",
        "        # x1 = mapping_to_target_range(x1, -90.0, 90.0)\n",
        "\n",
        "        # x2 = self.last_in2(x)\n",
        "        # x2 = mapping_to_target_range(x2, -180.0, 180.0)\n",
        "       \n",
        "        x3 = self.last_in3(x)\n",
        "\n",
        "        x4 = self.last_in4(x)\n",
        "        # x4 = self.act4(x4)\n",
        "\n",
        "        x = torch.cat([x3,x4],1)\n",
        "        # x = torch.cat([x1,x2,x3,x4],1)\n",
        "        # x = self.out(x)\n",
        "        return x\n",
        "generator = GeneratorNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak_1jFIqQQZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapping_to_target_range(x, target_min, target_max) :\n",
        "  x02 = torch.tanh(x) + 1 # x in range(0,2)\n",
        "  scale = ( target_max-target_min )/2.\n",
        "  return  x02 * scale + target_min"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1JK8zzbwtxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda=True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    discriminator.cuda()\n",
        "    generator.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfxxaHj6s_Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    n.cuda()\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq1kmEMEfL9q",
        "colab_type": "text"
      },
      "source": [
        "We experimented with two different kinds of optimizers to see if it led to better results for the generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-l-W9ONtEQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_optimizer = optim.SGD(discriminator.parameters(), lr=0.0004, momentum=0.8)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD2ShBkQtGYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypAAnOIYybvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWXau-AKtIPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(optimizer, data, labels):\n",
        "    N = real_data.size(0)\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction = discriminator(data)\n",
        "    prediction.cuda()\n",
        "    \n",
        "    labels=labels.cuda()\n",
        "\n",
        "    error_total = loss(prediction, labels)\n",
        "    error_total.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error and predictions for real and fake inputs\n",
        "    return error_total, prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE6ASu6Vf2WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_generator(optimizer, fake_data, labels):\n",
        "    N = fake_data.size(0)\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #y_gen = np.ones(N)\n",
        "\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "    prediction.cuda()\n",
        "\n",
        "    labels=labels.cuda()\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction, labels)\n",
        "\n",
        "    error.backward()\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIRPghZ5HjZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_root = \"/content/drive/My Drive/Capstone Project/GAN-Capstone/\"\n",
        "checkpoint_dir = os.path.join(drive_root, \"checkpoints\")\n",
        "# your name here\n",
        "checkpoint_dir = os.path.join(checkpoint_dir, \"hrishi\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssW5VqahHnkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Checkpoints directory is\", checkpoint_dir)\n",
        "if os.path.exists(checkpoint_dir):\n",
        "  print(\"Checkpoints folder already exists\")\n",
        "else:\n",
        "  print(\"Creating a checkpoints directory\")\n",
        "  os.makedirs(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K83t3piJy9bF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -r /content/drive/My\\ Drive/Capstone\\ Project/GAN-Capstone/checkpoints/hrishi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pty4cPoqHt2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chkpts = os.listdir(checkpoint_dir)\n",
        "if chkpts:\n",
        "  latest = chkpts[0]\n",
        "  print(latest)\n",
        "  saved = torch.load(checkpoint_dir+'/'+latest)\n",
        "  generator.load_state_dict(saved['gen_state_dict'])\n",
        "  discriminator.load_state_dict(saved['disc_state_dict'])\n",
        "  g_optimizer.load_state_dict(saved['gen_optimizer_state_dict'])\n",
        "  d_optimizer.load_state_dict(saved['disc_optimizer_state_dict'])\n",
        "  current_epoch = saved['epoch']+1\n",
        "  g_error = saved['gen_loss']\n",
        "  d_error = saved['disc_loss']\n",
        "else:\n",
        "  current_epoch = 0\n",
        "\n",
        "current_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VwrV6XZ66nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jcRsDpmdSyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(current_epoch,num_epochs):\n",
        "  results = pd.DataFrame(columns=['Prect','QBP','TBP'])\n",
        "  for n_batch,real_batch in enumerate(data_loader):\n",
        "    N = real_batch.size(0)\n",
        "    \n",
        "    # 1. Train Discriminator\n",
        "    real_data = real_batch\n",
        "    real_data.cuda()\n",
        "    \n",
        "    # Generate fake data and detach \n",
        "    # (so gradients are not calculated for generator)\n",
        "    noi=noise(N)\n",
        "    noi.cuda()\n",
        "\n",
        "    fake_data = generator(noi).detach()\n",
        "    fake_data.cuda()\n",
        "\n",
        "    #Generate real data and label it as 1, Train on real data\n",
        "    X1= np.array(real_data)\n",
        "    X1_torch = Variable(torch.from_numpy(X1).float())\n",
        "    X1_torch.cuda()\n",
        "\n",
        "    y_dis_1=np.ones(N)\n",
        "    y_torch_1 = Variable(torch.from_numpy(y_dis_1).float())\n",
        "    y_torch_1.cuda()\n",
        "    \n",
        "    d_error_1, d_pred_1 = train_discriminator(d_optimizer, X1_torch ,y_torch_1)\n",
        "    \n",
        "    # Label Fake data as 0, train on fake data\n",
        "    fake_data_temp=fake_data.cpu()\n",
        "    X2= np.array(fake_data_temp)\n",
        "    X2_torch = Variable(torch.from_numpy(X2).float())\n",
        "    X2_torch.cuda()\n",
        "\n",
        "    y_dis_2=np.zeros(N)\n",
        "    y_dis_2[:N]=0\n",
        "    y_torch_2 = Variable(torch.from_numpy(y_dis_2).float())\n",
        "    y_torch_2.cuda()\n",
        "\n",
        "    d_error_2, d_pred_2 = train_discriminator(d_optimizer, X2_torch ,y_torch_2)\n",
        "\n",
        "    #Add real and fake errors\n",
        "    d_error=d_error_1+d_error_2\n",
        "    \n",
        "\n",
        "    # 2. Train Generator\n",
        "    fake_data = generator(noise(N))\n",
        "  \n",
        "    fake_data.cuda()\n",
        "    \n",
        "    y_gen = np.ones(N)\n",
        "    y_torch_gen = Variable(torch.from_numpy(y_gen).float())\n",
        "    y_torch_gen.cuda()\n",
        "\n",
        "    g_error = train_generator(g_optimizer, fake_data, y_torch_gen)\n",
        "    \n",
        "\n",
        "    if (n_batch) % 100 == 0: \n",
        "      #Print results for every 100 epochs\n",
        "      print('Epoch: {},\\nDiscriminator Loss: {},\\nGenerator Loss: {},\\nGenerated Data: {}'.format(epoch+1,\n",
        "                                                                                               d_error.cpu().detach().numpy(),\n",
        "                                                                                               g_error.cpu().detach().numpy(),\n",
        "                                                                                               fake_data[0].cpu().detach().numpy()))\n",
        "\n",
        "\n",
        "    results = results.append(pd.DataFrame(fake_data.tolist(), columns=results.columns))\n",
        "\n",
        "  checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pt')\n",
        "\n",
        "  torch.save({'epoch': epoch,\n",
        "              'gen_state_dict': generator.state_dict(),\n",
        "              'disc_state_dict': discriminator.state_dict(),\n",
        "              'gen_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "              'disc_optimizer_state_dict': d_optimizer.state_dict(),\n",
        "              'gen_loss': g_error,\n",
        "              'disc_loss': d_error,},\n",
        "             checkpoint_path)\n",
        "  \n",
        "  pickle.dump(results, open('results_diff_optim_hrishi.pkl', 'wb'))\n",
        "  print('Saved model at ', checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPCuDT4r4XwI",
        "colab_type": "text"
      },
      "source": [
        "**Explore Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4vRE_QmVR0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = pickle.load(open('results_diff_optim_hrishi.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFsI9xu1r9_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGAtRTsV5Hqf",
        "colab_type": "text"
      },
      "source": [
        "**Inverse Transform**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zmUZj1U5PmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q = results.QBP**4\n",
        "p = s.inv_boxcox(results.Prect, 0.1)\n",
        "t = results.TBP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUFTJv73DufN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(results['Prect'], density=True, bins=20)\n",
        "plt.xlabel('Predicted PRECT')\n",
        "plt.ylabel('Density')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKocLH-9OQ_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = pd.concat([p.reset_index(drop=True),q.reset_index(drop=True),t.reset_index(drop=True)], axis=1)\n",
        "ans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt4_wMgK5yuo",
        "colab_type": "text"
      },
      "source": [
        "**Graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ-CxkqDV73H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist((d_non_zero.PRECT_NEW), density=True, bins=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVHNap8bOi76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(ans.QBP, ans.Prect, alpha=0.2)\n",
        "plt.xlabel('QBP')\n",
        "plt.ylabel('PRECT')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o63NypGnPDVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(ans.QBP, ans.Prect, alpha=0.2)\n",
        "plt.xlim(ans.QBP.min(), ans.QBP.max())\n",
        "plt.ylim(ans.Prect.min(), ans.Prect.max())\n",
        "plt.xlabel('QBP')\n",
        "plt.ylabel('PRECT')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMMid0KGPQO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(ans.QBP, ans.Prect, alpha=0.2)\n",
        "plt.xlim(1.246195e-05, 7.329976e-03)\n",
        "plt.ylim(1.999409e-20, 4.066384e-06)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQgUmIZ_QIjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(results.TBP, ans.Prect, alpha=0.2)\n",
        "plt.xlim(results.TBP.min(), results.TBP.max())\n",
        "plt.ylim(ans.Prect.min(), ans.Prect.max())\n",
        "plt.xlabel('TBP')\n",
        "plt.ylabel('PRECT')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7yjK8PPQPag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(results['Prect'], density=True, bins=20)\n",
        "plt.xlabel('Predicted PRECT')\n",
        "plt.ylabel('Density')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oibqp4p8QPx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(results.QBP, density=True, bins=20)\n",
        "plt.xlabel('Predicted QBP')\n",
        "plt.ylabel('Density')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqoc7vjaUDg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(results[(results.Prect >= d_non_zero.PRECT_NEW.min()) & (results.Prect <= d_non_zero.PRECT_NEW.max())]['Prect'], density=True, bins=20)\n",
        "#plt.xlim(-10,-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFmrcfVbL3ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(ans.QBP, ans.Prect, alpha=0.2)\n",
        "plt.xlabel('QBP')\n",
        "plt.ylabel('PRECT')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBdUmePOMieX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(ans.QBP, ans.Prect, alpha=0.2)\n",
        "plt.xlim(ans.QBP.min(), ans.QBP.max())\n",
        "plt.ylim(ans.Prect.min(), ans.Prect.max())\n",
        "plt.xlabel('QBP')\n",
        "plt.ylabel('PRECT')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocC2ggLEqFWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans_sorted = ans.sort_values(by='QBP')\n",
        "prect_vars_result = []\n",
        "qbp_bins_result_str = []\n",
        "for split in np.array_split(ans_sorted,10,axis = 0):\n",
        "  prect_vars_result.append(np.std(split.Prect)**2)\n",
        "  qbp_bins_result_str.append(\"{:.3f}\".format(split.QBP.min()*(10**3))+\" - \"+\"{:.3f}\".format(split.QBP.max()*(10**3)))\n",
        "\n",
        "plt.plot(prect_vars_result)\n",
        "plt.xticks(list(range(0,10)),labels=qbp_bins_result_str,rotation=90)\n",
        "plt.xlabel('QBP Range (1e-3)')\n",
        "plt.ylabel('PRECT Variance')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}